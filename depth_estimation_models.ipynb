{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DPT models comaprison to analyse the characteristic d vs 1/z behaviour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, AutoModelForDepthEstimation, DPTForDepthEstimation\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import rawpy\n",
    "from IPython.display import display, HTML\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "import cv2\n",
    "from sklearn.preprocessing import normalize\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "import random\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from matplotlib.colors import to_rgb\n",
    "from PUDE.PUDE_implementation import load_model as load_PUDE_model\n",
    "\n",
    "# 10 random images from each dataset, pre-selected using random without a seed, so the same images are used for all models\n",
    "random_images = {'D1': ['T_S03265.ARW', 'T_S03376.ARW', 'T_S03386.ARW', 'T_S03305.ARW', 'T_S03515.ARW', 'T_S03175.ARW', 'T_S03116.ARW', 'T_S03338.ARW', 'T_S03330.ARW', 'T_S03291.ARW'],\n",
    "                 'D3': ['T_S04900.ARW', 'T_S04857.ARW', 'T_S04871.ARW', 'T_S04870.ARW', 'T_S04923.ARW', 'T_S04874.ARW', 'T_S04866.ARW', 'T_S04904.ARW', 'T_S04876.ARW', 'T_S04890.ARW'],\n",
    "                 'D5': ['LFT_3384.NEF', 'LFT_3381.NEF', 'LFT_3396.NEF', 'LFT_3392.NEF', 'LFT_3375.NEF', 'LFT_3414.NEF', 'LFT_3388.NEF', 'LFT_3385.NEF', 'LFT_3380.NEF', 'LFT_3412.NEF']}\n",
    "# models and their paths, pude has a local path, the rest are from huggingface\n",
    "models = {\"pude\": \"PUDE/weightsave/final2/finall2.pth\", \"depth_anything\": \"nielsr/depth-anything-small\",  \"dpt3_1\": \"Intel/dpt-swinv2-large-384\"}\n",
    "seed = 42\n",
    "default_image_dim = (576,384)\n",
    "datasets_dir = 'Datasets'\n",
    "results_dir = 'Results'\n",
    "nsample_images = 10\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device is\", device)\n",
    "\n",
    "def display_image_small(im, width=500):\n",
    "    w, h = im.size\n",
    "    height = int(h * (width / w))\n",
    "    image = im.resize((width, height))\n",
    "    display(image)\n",
    "\n",
    "def open_image(path, depth_path, result_ground_truth_image_path,img_dim, save_ground_truth=False, display=False):\n",
    "    depth_img = tiff.imread(depth_path)\n",
    "    depth_img = resize(depth_img, (img_dim[1], img_dim[0]), order=1, mode='constant', anti_aliasing=False)\n",
    "    formatted = (depth_img * 255 / np.max(depth_img)).astype(\"uint8\")\n",
    "    colored_depth = cv2.applyColorMap(formatted, cv2.COLORMAP_INFERNO)[:, :, ::-1]\n",
    "    depth = Image.fromarray(colored_depth)\n",
    "    if save_ground_truth:\n",
    "        # save the ground truth image\n",
    "        depth.save(result_ground_truth_image_path, format='png')\n",
    "    # Display the shape of the image array\n",
    "    with rawpy.imread(path) as raw_image:\n",
    "        rgb = raw_image.postprocess()\n",
    "        image = Image.fromarray(rgb)\n",
    "        # print(f\"Original image size: {w}x{h}\")\n",
    "        # print(f\"Resized image size: {width}x{height}\")\n",
    "        image = image.resize(img_dim)\n",
    "        if display:\n",
    "            print(\"raw image and ground truth\")\n",
    "            display_image_small(image)            \n",
    "            display_image_small(depth)\n",
    "    return image, depth_img\n",
    "\n",
    "def preprocess_image(image_processor, image):\n",
    "    # prepare image for the model\n",
    "    inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "    return inputs\n",
    "\n",
    "def predict_depth(model, inputs):\n",
    "    #forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # output is a tensor\n",
    "        if isinstance(outputs, torch.Tensor):\n",
    "            predicted_depth = outputs\n",
    "        else:\n",
    "         predicted_depth = outputs.predicted_depth\n",
    "    return predicted_depth\n",
    "\n",
    "def post_process_depth(depth, image, predicted_depth_path, display=False):\n",
    "    # interpolate to original size\n",
    "    prediction = torch.nn.functional.interpolate(\n",
    "        depth.unsqueeze(1),\n",
    "        size=image.size[::-1],\n",
    "        mode=\"bicubic\",\n",
    "        align_corners=False,\n",
    "    )\n",
    "\n",
    "    # visualize the prediction\n",
    "    output = prediction.squeeze().cpu().numpy()\n",
    "    formatted = (output * 255 / np.max(output)).astype(\"uint8\")\n",
    "    colored_depth = cv2.applyColorMap(formatted, cv2.COLORMAP_INFERNO)[:, :, ::-1]\n",
    "    depth = Image.fromarray(colored_depth)\n",
    "    depth.save(predicted_depth_path, format='png')\n",
    "    if display:\n",
    "        display_image_small(depth)\n",
    "    return output, colored_depth, depth\n",
    "\n",
    "\n",
    "def plot_one_over_z_vs_d(actual_depth, model_output, save_folder, img_name):\n",
    "    # Remove zero values\n",
    "    z = actual_depth.flatten()\n",
    "    d = model_output.flatten()\n",
    "\n",
    "    non_zero = np.where(z > 0.33)\n",
    "    z = 1/z[non_zero]\n",
    "    d = d[non_zero]\n",
    "\n",
    "    # normalise d\n",
    "    d = d/np.max(d)\n",
    "\n",
    "    plt.figure()\n",
    "    # Scatter plot\n",
    "    plt.scatter(z, d, s=1)\n",
    "    plt.xlabel(\"1/z\")\n",
    "    plt.ylabel(\"d\")\n",
    "   \n",
    "    # Linear regression\n",
    "    result = linregress(z, d)\n",
    "    \n",
    "    # Line of best fit\n",
    "    fit_x = np.linspace(np.min(z), np.max(z), 100)\n",
    "    fit_y = result.slope * fit_x + result.intercept\n",
    "    # new figure\n",
    "  \n",
    "    plt.plot(fit_x, fit_y, '-r', label='Line of best fit, r = {:.3f}'.format(result.rvalue))\n",
    "    \n",
    "    # Display R-squared value\n",
    "    plt.legend()\n",
    "    plt.title(f\"1/z vs d for {img_name}\")\n",
    "    # plt.show( )\n",
    "    plt.savefig(save_folder, dpi=100, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    return result.rvalue\n",
    "\n",
    "def plot_residuals(actual_depth, model_output, img_name, save_folder, plot_without_noise_path):\n",
    "    # Remove zero values\n",
    "    z = actual_depth.flatten()\n",
    "    d = model_output.flatten()\n",
    "    # print(z.shape)\n",
    "    non_zero_mask = z > 0.33\n",
    "    # non_zero = np.where(z > 0.33)\n",
    "    z = 1/z[non_zero_mask]\n",
    "    d = d[non_zero_mask]\n",
    "\n",
    "    # normalise d\n",
    "    d = d/np.max(d)\n",
    "\n",
    "    # Linear regression\n",
    "    result = linregress(z, d)\n",
    "\n",
    "    # Calculate residuals\n",
    "    residuals = d - result.slope * z - result.intercept\n",
    "\n",
    "    abs_residuals = np.abs(residuals)\n",
    "    threshold = 3.5 * np.std(abs_residuals)\n",
    "\n",
    "    # Identify the outliers\n",
    "    outliers_mask = abs_residuals > threshold\n",
    "    outliers = np.column_stack((z[outliers_mask], residuals[outliers_mask]))\n",
    "    combined_mask = combine_masks([non_zero_mask, outliers_mask])\n",
    "    # print(combined_mask.shape)\n",
    "    # Apply k-means clustering with k=3 to the outliers\n",
    "    # kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(outliers)\n",
    "    dbscan = DBSCAN(eps=0.2, min_samples=10).fit(outliers)\n",
    "\n",
    "    # Plot the outliers\n",
    "    plt.figure()\n",
    "    # plt.scatter(z, residuals, color='blue', label='Data points', s=0.5) \n",
    "    # 10 colours\n",
    "    n_clusters = len(set(dbscan.labels_)) if -1 not in dbscan.labels_ else len(set(dbscan.labels_)) - 1\n",
    "    colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, n_clusters)]\n",
    "    # append black for outliers \n",
    "    if -1 in dbscan.labels_:\n",
    "        colors.append((0, 0, 0, 1))\n",
    "    rgb_colors = [to_rgb(color) for color in colors]\n",
    "\n",
    "\n",
    "    clusters_masks = []\n",
    "    for i in set(dbscan.labels_):\n",
    "        cluster_mask = dbscan.labels_ == i\n",
    "        clusters_masks.append(combine_masks([combined_mask, cluster_mask]).reshape(actual_depth.shape))\n",
    "        plt.scatter(outliers[cluster_mask, 0], outliers[cluster_mask, 1], color=colors[i], label=f'Cluster {i}', s=0.5)\n",
    " \n",
    "    # plt.scatter(z[outliers_mask], residuals[outliers_mask], color='red', label='Outliers', s=0.5)\n",
    "    plt.xlabel('1/z')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.legend()\n",
    "    plt.title(f'Outliers for {img_name}')\n",
    "    # plt.show()\n",
    "    plt.savefig(save_folder, dpi=100, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # now remove the noise cluster and replot the linear regression\n",
    "    if -1 in dbscan.labels_:\n",
    "        noise_mask = dbscan.labels_ == -1\n",
    "        non_noise_mask = ~combine_masks([outliers_mask, noise_mask])\n",
    "        z = z[non_noise_mask]\n",
    "        d = d[non_noise_mask]\n",
    "        result = linregress(z, d)\n",
    "        fit_x = np.linspace(np.min(z), np.max(z), 100)\n",
    "        fit_y = result.slope * fit_x + result.intercept\n",
    "        plt.figure()\n",
    "        plt.scatter(z, d, s=1)\n",
    "        plt.plot(fit_x, fit_y, '-r', label='Line of best fit, r = {:.3f}'.format(result.rvalue))\n",
    "        plt.xlabel(\"1/z\")\n",
    "        plt.ylabel(\"d\")\n",
    "        plt.legend()\n",
    "        plt.title(f\"1/z vs d for {img_name} without noise\")\n",
    "        plt.savefig(plot_without_noise_path, dpi=100, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "    return clusters_masks, rgb_colors\n",
    "    \n",
    "\n",
    "def combine_masks(masks)-> np.ndarray:\n",
    "    m = masks[0].copy()\n",
    "    for m2 in masks[1:]:\n",
    "        # Combine masks\n",
    "        j = 0\n",
    "        for i in range(len(m)):\n",
    "            if m[i] == True:\n",
    "                m[i] = m[i] and m2[j]\n",
    "                j+=1\n",
    "    return m\n",
    "\n",
    "def underwater_depth_model_analysis(model, image_processor, image_name, dataset_name, raw_image_path, actual_depth_path, results_path, img_dim=(664,443), save_ground_truth=False, display=False):\n",
    "    # initialise model\n",
    "    plot_path = f'{results_path}/plot/{image_name}.PNG'\n",
    "    result_ground_truth_image_path = f'Datasets/{dataset_name}/depth_png/{image_name}.png'\n",
    "    predicted_depth_path = f'{results_path}/predicted_depth/{image_name}.png'\n",
    "    outlier_cluster_path = f'{results_path}/outlier_cluster/{image_name}.PNG'\n",
    "    outlier_image_path = f'{results_path}/outlier_image/{image_name}.PNG'\n",
    "    plot_without_noise_path = f'{results_path}/plot_without_noise/{image_name}.PNG'\n",
    "  \n",
    "    raw_image, actual_depth = open_image(path=raw_image_path, depth_path=actual_depth_path, \n",
    "                                         result_ground_truth_image_path=result_ground_truth_image_path, \n",
    "                                         img_dim=img_dim, save_ground_truth=save_ground_truth, display=display)\n",
    "    inputs = preprocess_image(image_processor=image_processor, image=raw_image)\n",
    "    predicted_depth = predict_depth(model=model, inputs=inputs)\n",
    "    model_output, formatted, depth_im = post_process_depth(depth=predicted_depth, image=raw_image, predicted_depth_path=predicted_depth_path, display=display)\n",
    "    rvalue = plot_one_over_z_vs_d(actual_depth, model_output, plot_path, image_name)\n",
    "    outlier_cluster_masks, colors = plot_residuals(actual_depth, model_output, image_name, outlier_cluster_path, plot_without_noise_path)\n",
    "    display_outliers_on_image(np.array(raw_image), outlier_cluster_masks, image_name, outlier_image_path, colors=colors)\n",
    "    return rvalue\n",
    "\n",
    "# def display_outliers_on_image(image, outlier_cluster_masks, img_name, save_folder, colors):\n",
    "#     # change the colours of the pixels in the image\n",
    "#     # red, yellow, pink, black\n",
    "#     for i, mask in enumerate(outlier_cluster_masks):\n",
    "#         # print((np.array(colors[i])*255).astype(int))\n",
    "#         # print(np.rint(np.ndarray(colors[i])* 255).astype(int), type(np.rint(np.ndarray(colors[i])* 255).astype(int)))\n",
    "#         image[mask] = (np.rint(np.array(colors[i])*255)).astype(int)\n",
    "#     img = Image.fromarray(image)\n",
    "#     img.save(save_folder, format='png')\n",
    "\n",
    "def overlay_color(image, mask, color, alpha):\n",
    "    \"\"\"\n",
    "    Overlay a semi-transparent color over the specified mask region in the image.\n",
    "\n",
    "    Parameters:\n",
    "    - image: Original image as a numpy array.\n",
    "    - mask: Boolean mask indicating the region to overlay the color on.\n",
    "    - color: RGB color tuple.\n",
    "    - alpha: Opacity level for the overlay color (0.0 - 1.0).\n",
    "    \n",
    "    Returns:\n",
    "    - Image with the overlay applied.\n",
    "    \"\"\"\n",
    "    # Convert the color to float values\n",
    "    color_float = np.array(color) * 255\n",
    "    \n",
    "    image[mask] = ((1 - alpha) * image[mask] + alpha * color_float).astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def display_outliers_on_image(image, outlier_cluster_masks, img_name, save_folder, colors, alpha=0.7):\n",
    "    \"\"\"\n",
    "    Overlay semi-transparent colors over specified regions in the image based on outlier cluster masks.\n",
    "\n",
    "    Parameters:\n",
    "    - image: Original image as a numpy array.\n",
    "    - outlier_cluster_masks: List of boolean masks indicating the regions to overlay the colors on.\n",
    "    - img_name: Name of the image (not used in this function).\n",
    "    - save_folder: Folder path to save the resulting image (not used in this function).\n",
    "    - colors: List of RGB color tuples corresponding to the colors to overlay.\n",
    "    - alpha: Opacity level for the overlay colors (0.0 - 1.0).\n",
    "    \n",
    "    Returns:\n",
    "    - Image with the overlay applied.\n",
    "    \"\"\"\n",
    "    for mask, color in zip(outlier_cluster_masks, colors):\n",
    "        image = overlay_color(image, mask, color, alpha)\n",
    "    \n",
    "    img = Image.fromarray(image)\n",
    "    img.save(save_folder, format='png')\n",
    "    \n",
    "\n",
    "def get_PUDE_image_processor(transform):\n",
    "    def image_processor_PUDE(images:Image, return_tensors=\"pt\"):\n",
    "        # if images not np array\n",
    "        if type(images) != np.ndarray:\n",
    "            images = np.array(images)\n",
    "        net_img = images\n",
    "        net_img = transform({\"image\": net_img})[\"image\"]\n",
    "        net_img = torch.from_numpy(net_img)\n",
    "        # reshape the tensor to include batch size of 1\n",
    "        net_img = net_img.reshape((1, *net_img.shape))\n",
    "        return {'x':net_img}\n",
    "       \n",
    "    return image_processor_PUDE\n",
    "\n",
    "\n",
    "def get_model_image_processor_pair(model_name, model_path, device):\n",
    "    if model_name == \"pude\":\n",
    "        model, transform = load_PUDE_model(model_path, device)\n",
    "        image_processor = get_PUDE_image_processor(transform)\n",
    "    else:\n",
    "        image_processor = AutoImageProcessor.from_pretrained(model_path)\n",
    "        model = AutoModelForDepthEstimation.from_pretrained(model_path)\n",
    "    \n",
    "    return model, image_processor\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "def process_datasets(datasets_dir, results_dir, model_name, nsample_images, random_images, image_processor, model, default_image_dim, save_ground_truth):\n",
    "    results_paths = {}\n",
    "    mean_r_values = {}\n",
    "    raw_image_count = 0\n",
    "\n",
    "    for dataset_dir in os.listdir(datasets_dir):\n",
    "        dataset_path = datasets_dir + '/' + dataset_dir\n",
    "        dataset_name = dataset_dir\n",
    "        results_paths[dataset_name] = results_dir + '/' + model_name + '/' + dataset_name\n",
    "        \n",
    "        if not os.path.exists(results_paths[dataset_name]):\n",
    "            os.makedirs(results_paths[dataset_name] + '/plot')\n",
    "            os.makedirs(results_paths[dataset_name] + '/predicted_depth')\n",
    "            os.makedirs(results_paths[dataset_name] + '/outlier_cluster')\n",
    "            os.makedirs(results_paths[dataset_name] + '/outlier_image')\n",
    "            os.makedirs(results_paths[dataset_name] + '/plot_without_noise')\n",
    "        \n",
    "        raw_image_dir = dataset_path + '/Raw'\n",
    "        depth_image_dir = dataset_path + '/depth'\n",
    "        \n",
    "        if os.path.isdir(raw_image_dir):\n",
    "            mean_r_values[(model_name, dataset_name)] = 0\n",
    "            \n",
    "            if dataset_name not in random_images.keys():  \n",
    "                all_raw_images = os.listdir(raw_image_dir)\n",
    "                random_images[dataset_name] = random.sample(all_raw_images, nsample_images)\n",
    "                \n",
    "            for raw_image in random_images[dataset_name]:\n",
    "                raw_image_path = raw_image_dir + '/' + raw_image\n",
    "                raw_image_name = raw_image[:-4]\n",
    "                depth_image_path = depth_image_dir + '/depth' + raw_image_name + '.tif'\n",
    "    \n",
    "                r_value = underwater_depth_model_analysis(\n",
    "                    model=model, \n",
    "                    image_processor=image_processor, \n",
    "                    image_name=raw_image_name, \n",
    "                    dataset_name=dataset_name, \n",
    "                    raw_image_path=raw_image_path, \n",
    "                    actual_depth_path=depth_image_path, \n",
    "                    results_path=results_paths[dataset_name], \n",
    "                    img_dim=default_image_dim, \n",
    "                    save_ground_truth=save_ground_truth, \n",
    "                    display=False\n",
    "                )\n",
    "                mean_r_values[(model_name, dataset_name)] += r_value\n",
    "                raw_image_count += 1\n",
    "                \n",
    "                if raw_image_count % 10 == 0:\n",
    "                    print(f\"Processed {raw_image_count} images.\")\n",
    "                    \n",
    "            mean_r_values[(model_name, dataset_name)] /= nsample_images\n",
    "            \n",
    "    return results_paths, mean_r_values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Driver Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PUDE model\n",
      "Loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\mukul\\anaconda3\\lib\\site-packages\\timm\\models\\_factory.py:117: UserWarning: Mapping deprecated model name vit_base_resnet50_384 to current vit_base_r50_s16_384.orig_in21k_ft_in1k.\n",
      "  model = create_fn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 images.\n",
      "Processed 20 images.\n",
      "Processed 30 images.\n",
      "Finished processing PUDE model. Mean r values are: \n",
      "({'D1': 'Results/PUDE/D1', 'D3': 'Results/PUDE/D3', 'D5': 'Results/PUDE/D5'}, {('PUDE', 'D1'): 0.7620195702750033, ('PUDE', 'D3'): 0.9475662751787077, ('PUDE', 'D5'): 0.8773996758721416})\n",
      "Processing depth_anything model\n",
      "Processed 10 images.\n",
      "Processed 20 images.\n",
      "Processed 30 images.\n",
      "Finished processing depth_anything model. Mean r values are: \n",
      "({'D1': 'Results/depth_anything/D1', 'D3': 'Results/depth_anything/D3', 'D5': 'Results/depth_anything/D5'}, {('depth_anything', 'D1'): 0.7866275595978973, ('depth_anything', 'D3'): 0.951171442924926, ('depth_anything', 'D5'): 0.8836193939428867})\n",
      "Processing dpt3_1 model\n",
      "Processed 10 images.\n",
      "Processed 20 images.\n",
      "Processed 30 images.\n",
      "Finished processing dpt3_1 model. Mean r values are: \n",
      "({'D1': 'Results/dpt3_1/D1', 'D3': 'Results/dpt3_1/D3', 'D5': 'Results/dpt3_1/D5'}, {('dpt3_1', 'D1'): 0.8947625136868865, ('dpt3_1', 'D3'): 0.9565786957374499, ('dpt3_1', 'D5'): 0.8749631295318923})\n",
      "{'PUDE': ({'D1': 'Results/PUDE/D1', 'D3': 'Results/PUDE/D3', 'D5': 'Results/PUDE/D5'}, {('PUDE', 'D1'): 0.7620195702750033, ('PUDE', 'D3'): 0.9475662751787077, ('PUDE', 'D5'): 0.8773996758721416}), 'depth_anything': ({'D1': 'Results/depth_anything/D1', 'D3': 'Results/depth_anything/D3', 'D5': 'Results/depth_anything/D5'}, {('depth_anything', 'D1'): 0.7866275595978973, ('depth_anything', 'D3'): 0.951171442924926, ('depth_anything', 'D5'): 0.8836193939428867}), 'dpt3_1': ({'D1': 'Results/dpt3_1/D1', 'D3': 'Results/dpt3_1/D3', 'D5': 'Results/dpt3_1/D5'}, {('dpt3_1', 'D1'): 0.8947625136868865, ('dpt3_1', 'D3'): 0.9565786957374499, ('dpt3_1', 'D5'): 0.8749631295318923})}\n"
     ]
    }
   ],
   "source": [
    "r_values = []\n",
    "for model_name, model_path in models.items():\n",
    "    print(f\"Processing {model_name} model\")\n",
    "    model, image_processor = get_model_image_processor_pair(model_name, model_path, device)\n",
    "    mean_r_values = process_datasets(datasets_dir, results_dir, model_name, nsample_images, random_images, image_processor, model, default_image_dim, save_ground_truth=False)\n",
    "    r_values.append(mean_r_values)\n",
    "    print(f\"Finished processing {model_name} model. Mean r values are: \\n{mean_r_values}\")\n",
    "\n",
    "for r_value in r_values:\n",
    "    print(r_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
