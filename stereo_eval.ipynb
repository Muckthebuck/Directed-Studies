{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------rock_garden1 Results-------------------\n",
      "new_unimatch_small_model_FLsea_Canyon1_new_pude_edge_aware_loss_cosine_scheduler_AdamW_betas_2_0_0.08_0.4_lr_0.0001_epochs_3: \n",
      "dict_keys(['abs_rel_error', 'squared_rel_error', 'rmse', 'rmse_log', 'silog', 'accuracy_1.05', 'accuracy_1.05^2', 'accuracy_1.05^3', 'r_value'])\n",
      "[8.33919913e+00 6.85313350e+07 4.17173058e+00 9.74654263e-01\n",
      " 7.75176425e-01 8.81878963e-02 1.70458699e-01 2.44999102e-01\n",
      " 8.16104244e-01]\n",
      "------------------------------------------------------------\n",
      "-------------------rock_garden2 Results-------------------\n",
      "new_unimatch_small_model_FLsea_Canyon1_new_pude_edge_aware_loss_cosine_scheduler_AdamW_betas_2_0_0.08_0.4_lr_0.0001_epochs_3: \n",
      "dict_keys(['abs_rel_error', 'squared_rel_error', 'rmse', 'rmse_log', 'silog', 'accuracy_1.05', 'accuracy_1.05^2', 'accuracy_1.05^3', 'r_value'])\n",
      "[9.24047588e-01 2.54803311e+04 3.62587758e+00 6.16864619e-01\n",
      " 5.23665452e-01 1.12434281e-01 2.19077789e-01 3.18391871e-01\n",
      " 8.13296538e-01]\n",
      "------------------------------------------------------------\n",
      "-------------------rock_garden1 Results-------------------\n",
      "new_unimatch_small_model_FLsea_Canyon1_new_pude_edge_aware_loss_cosine_scheduler_AdamW_betas_2_0_0.4_0.4_lr_0.0001_epochs_3: \n",
      "dict_keys(['abs_rel_error', 'squared_rel_error', 'rmse', 'rmse_log', 'silog', 'accuracy_1.05', 'accuracy_1.05^2', 'accuracy_1.05^3', 'r_value'])\n",
      "[7.24568523e+00 7.81081940e+04 3.79250559e+00 1.00865058e+00\n",
      " 8.57673465e-01 1.05633304e-01 2.09579002e-01 3.08778212e-01\n",
      " 8.58032792e-01]\n",
      "------------------------------------------------------------\n",
      "-------------------rock_garden2 Results-------------------\n",
      "new_unimatch_small_model_FLsea_Canyon1_new_pude_edge_aware_loss_cosine_scheduler_AdamW_betas_2_0_0.4_0.4_lr_0.0001_epochs_3: \n",
      "dict_keys(['abs_rel_error', 'squared_rel_error', 'rmse', 'rmse_log', 'silog', 'accuracy_1.05', 'accuracy_1.05^2', 'accuracy_1.05^3', 'r_value'])\n",
      "[9.76059599e-01 1.86538331e+04 3.47558252e+00 6.42344639e-01\n",
      " 5.60339442e-01 1.14654322e-01 2.24466008e-01 3.27789580e-01\n",
      " 8.41303063e-01]\n",
      "------------------------------------------------------------\n",
      "-------------------rock_garden1 Results-------------------\n",
      "new_unimatch_small_model_FLsea_Canyon1_new_pude_edge_aware_loss_cosine_scheduler_AdamW_betas_2_0_0.1_0.5_lr_0.0001_epochs_3: \n",
      "dict_keys(['abs_rel_error', 'squared_rel_error', 'rmse', 'rmse_log', 'silog', 'accuracy_1.05', 'accuracy_1.05^2', 'accuracy_1.05^3', 'r_value'])\n",
      "[1.09207076e+01 2.24506994e+08 4.27572044e+00 1.11261630e+00\n",
      " 8.99317053e-01 8.75568874e-02 1.72009626e-01 2.49735430e-01\n",
      " 8.10139931e-01]\n",
      "------------------------------------------------------------\n",
      "-------------------rock_garden2 Results-------------------\n",
      "new_unimatch_small_model_FLsea_Canyon1_new_pude_edge_aware_loss_cosine_scheduler_AdamW_betas_2_0_0.1_0.5_lr_0.0001_epochs_3: \n",
      "dict_keys(['abs_rel_error', 'squared_rel_error', 'rmse', 'rmse_log', 'silog', 'accuracy_1.05', 'accuracy_1.05^2', 'accuracy_1.05^3', 'r_value'])\n",
      "[1.02737882e+00 2.87491646e+02 3.88152861e+00 6.77510902e-01\n",
      " 5.69832668e-01 1.07043629e-01 2.07626275e-01 3.02232955e-01\n",
      " 7.97129843e-01]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import Pude_training_loop.loss_functions_torch as loss_functions\n",
    "import Pude_training_loop.pude_utils as pude_utils\n",
    "import Pude_training_loop.model_training as model_training\n",
    "import monocular_stereo_matching.stereo_dataset_loader as data_loader\n",
    "from monocular_stereo_matching.stereo_pair_gen import Stereo_Pair_Generator\n",
    "import torch\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import monocular_stereo_matching.stereo_eval as stereo_eval\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model_path = \"new_unimatch_model_pude_AdamW_beta_60_600_alphas_4_0_4_epochs_3_lr_1e-6.pth\"\n",
    "model_path =\"new_unimatch_model_Adamw_betas_60_600,_alphas_4_0_4_checkpoint_epoch_0_finished.pth\"\n",
    "\n",
    "# model_path = \"new_unimatch_model_cosine_scheduler_AdamW_betas_100_50,_alphas_4_0-4_4_lr_5e-6_epochs_3.pth\"\n",
    "# model_path = \"new_unimatch_model_cosine_scheduler_AdamW_betas_60_60,_alphas_4_0-4_8_lr_5e-6_epochs_3.pth\"\n",
    "# model_path = \"new_unimatch_model_cosine_scheduler_AdamW_betas_200_100,_alphas_4_0-4_4_lr_5e-6_epochs_3.pth\"\n",
    "datasets = [\"rock_garden1\", \"rock_garden2\"]\n",
    "# datasets = [\"canyon2\"]\n",
    "# datasets = [\"rock_garden2\"]\n",
    "# model_type = \"pude\"\n",
    "# new_model_type = \"new_pude\"\n",
    "# model_type = \"unimatch\"\n",
    "# new_model_type = \"unimatch\"\n",
    "\n",
    "# model_paths = [f\"new_unimatch_model_edge_aware_loss_cosine_scheduler_AdamW_betas_2_0_0.1_0.5_lr_1e-4_epochs_3.pth\",\n",
    "#                f\"new_unimatch_model_edge_aware_loss_cosine_scheduler_AdamW_betas_2_0_0_0.5_lr_1e-4_epochs_3.pth\", \n",
    "#                 f\"new_unimatch_model_edge_aware_loss_cosine_scheduler_AdamW_betas_2_0_0_0_lr_1e-4_epochs_3.pth\"]\n",
    "# model_paths_nums = [f\"new_combined_2_0_0.1_0.5_epochs_3_lr_1e-4\",\n",
    "#                     f\"new_combined_2_0_0_0.5_epochs_3_lr_1e-4\", \n",
    "#                     f\"new_combined_2_0_0_0_epochs_3_lr_1e-4\"]  \n",
    "\n",
    "\n",
    "# model_type = \"unimatch\"\n",
    "# new_model_type = \"unimatch\"\n",
    "\n",
    "# model_paths = [f\"new_unimatch_model_edge_aware_loss_cosine_scheduler_AdamW_betas_2_0_0.1_0.5_lr_1e-4_epochs_3.pth\"]\n",
    "# model_paths_nums = [f\"new_combined_2_0_0.1_0.5_epochs_3_lr_1e-4\"]\n",
    "\n",
    "model_type = \"unimatch_small\"\n",
    "new_model_type = \"unimatch_small\"\n",
    "\n",
    "model_paths = [\"new_unimatch_small_model_FLsea_Canyon1_new_pude_edge_aware_loss_cosine_scheduler_AdamW_betas_2_0_0.08_0.4_lr_0.0001_epochs_3.pth\",\n",
    "               \"new_unimatch_small_model_FLsea_Canyon1_new_pude_edge_aware_loss_cosine_scheduler_AdamW_betas_2_0_0.4_0.4_lr_0.0001_epochs_3.pth\",\n",
    "               \"new_unimatch_small_model_FLsea_Canyon1_new_pude_edge_aware_loss_cosine_scheduler_AdamW_betas_2_0_0.1_0.5_lr_0.0001_epochs_3.pth\"]\n",
    "model_paths_nums = [\"unimatch_small_2_0_0.08_0.4\",\n",
    "                    \"unimatch_small_2_0_0.4_0.4\",\n",
    "                    \"unimatch_small_2_0_0.1_0.5\"]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0, len(model_paths)):\n",
    "    # model_path = f\"new_unimatch_model_edge_aware_loss_cosine_scheduler_AdamW_betas_1_40_4_alphas_1_0.1_4_lr_5e-06_epoch_{i}.pth\"\n",
    "    # model_path  = f\"new_pude_model_Adam_betas_1_0-002,_alphas_1_0-1_1.pth\"\n",
    "    # model_path = f\"new_unimatch_model_edge_aware_loss_cosine_scheduler_AdamW_betas_4_0_0.1_0.5_lr_0.0001_epoch_{i}.pth\"\n",
    "    # model_path =  f\"new_unimatch_model_edge_aware_loss_cosine_scheduler_AdamW_betas_100_80_10_alphas_4_0-4_4_lr_5e-6_epochs_{i}.pth\"\n",
    "    # model_path =  \"new_unimatch_model_cosine_scheduler_AdamW_betas_300_400,_alphas_4_0-4_4_lr_5e-6_epochs_3.pth\"\n",
    "    # model_path = f\"new_unimatch_model_edge_aware_loss_cosine_scheduler_AdamW_betas_4_0_0.1_0.5_lr_1e-4_epoch_{i}.pth\"\n",
    "    # model_path_nums = f\"new_combined_4_0_0.1_0.5_epoch_{i}_lr_1e-4\"  \n",
    "    \n",
    "    model_path = model_paths[i]\n",
    "    model_path_nums = model_paths_nums[i]\n",
    "\n",
    "    # org_unimatch_model, org_unimatch_image_processor = model_training.get_model_image_processor_pair(model_name=model_type, model_path=model_training.models[model_type], device=device)\n",
    "    new_unimatch_model, new_unimatch_image_processor = model_training.get_model_image_processor_pair(model_name=new_model_type, model_path=model_path, device=device)\n",
    "    total_images = 100\n",
    "    for dataset_name in datasets:\n",
    "        # create the results folder if it doesnt exist\n",
    "        if not os.path.exists(f\"Results/FLSea/{dataset_name}/new_{model_type}_{model_path_nums}/images\"):\n",
    "            os.makedirs(f\"Results/FLSea/{dataset_name}/new_{model_type}_{model_path_nums}/images\")\n",
    "            os.makedirs(f\"Results/FLSea/{dataset_name}/new_{model_type}_{model_path_nums}/rplots\")\n",
    "            os.makedirs(f\"Results/FLSea/{dataset_name}/combined_{model_type}_{model_path_nums}/images\")\n",
    "        if not os.path.exists(f\"Results/FLSea/{dataset_name}/org_{model_type}/images\"):\n",
    "            os.makedirs(f\"Results/FLSea/{dataset_name}/org_{model_type}/images\")\n",
    "            os.makedirs(f\"Results/FLSea/{dataset_name}/org_{model_type}/rplots\")\n",
    "\n",
    "       \n",
    "        dataset_names = [dataset_name]\n",
    "        save_ground_truth = False\n",
    "\n",
    "        dataset_loader = data_loader.DatasetLoader(total_num_pairs=total_images, dataset_names=dataset_names) # Initialize dataset loader with default parameters\n",
    "        stereo_pair_gen = Stereo_Pair_Generator(image_dim=model_training.default_image_dim)\n",
    "        stereo_evaluator = stereo_eval.StereoEval()\n",
    "\n",
    "\n",
    "        new_unimatch_results_path = f\"Results/FLSea/{dataset_name}/new_{model_type}_{model_path_nums}/images\"\n",
    "        org_unimatch_results_path = f\"Results/FLSea/{dataset_name}/org_{model_type}/images\"\n",
    "        combined_grid_path = f\"Results/FLSea/{dataset_name}/combined_{model_type}_{model_path_nums}/images\"\n",
    "        new_unimatch_results_rplt_path = f\"Results/FLSea/{dataset_name}/new_{model_type}_{model_path_nums}/rplots\"\n",
    "        org_unimatch_results_rplt_path = f\"Results/FLSea/{dataset_name}/org_{model_type}/rplots\"\n",
    "\n",
    "        # seed the torch\n",
    "        torch.manual_seed(model_training.seed)\n",
    "        np.random.seed(model_training.seed)\n",
    "\n",
    "\n",
    "        new_evals = np.zeros(len(stereo_evaluator.criteria_functions))\n",
    "        # org_evals = np.zeros(len(stereo_evaluator.criteria_functions))\n",
    "       \n",
    "\n",
    "        # orig_unimatch_results = []\n",
    "\n",
    "        def get_model_output(unimatch_model, unimatch_image_processor, input, ground_truth, valid_indices, device, rplot_path=None):\n",
    "            unimatch_output = model_training.get_model_output(model=unimatch_model, \n",
    "                                                            image_processor=unimatch_image_processor, \n",
    "                                                            raw_image=input, \n",
    "                                                            device=device, requires_grad=False)\n",
    "            unimatch_output = unimatch_output.cpu().detach().numpy().squeeze()\n",
    "            ground_truth_image = pude_utils.get_depth_as_image(ground_truth)\n",
    "            model_output_image = pude_utils.get_depth_as_image(unimatch_output)\n",
    "            diff_image = np.zeros_like(ground_truth)\n",
    "            diff_image[valid_indices] = np.abs(ground_truth[valid_indices]-unimatch_output[valid_indices])\n",
    "            abs_difference_image = pude_utils.get_depth_as_image(diff_image)\n",
    "            if model_type == \"unimatch\" or model_type == \"unimatch_small\":\n",
    "                left_image = Image.fromarray(input['image1'])\n",
    "            elif model_type == \"pude\" or model_type == \"depth_anything\"  :\n",
    "                left_image = Image.fromarray(input)\n",
    "            image_grid = pude_utils.make_image_grid_title(images=[left_image, ground_truth_image, model_output_image, abs_difference_image], \n",
    "                                                titles=[\"Left Image\", \"Ground Truth\", \"Model Output\", \"Absolute Difference\"],\n",
    "                                                rows=1, cols=4)\n",
    "            evals = stereo_evaluator.evaluate(ground_truth[valid_indices], unimatch_output[valid_indices],rplot_path=rplot_path)\n",
    "            return unimatch_output, model_output_image, evals, image_grid\n",
    "\n",
    "\n",
    "        for i in range(total_images):\n",
    "            left_image, right_image, ground_truth, valid_indices = dataset_loader[i]\n",
    "            # left_image = torch.tensor(left_image)\n",
    "            # right_image = torch.tensor(right_image)\n",
    "\n",
    "            if model_type == \"unimatch\" or model_type == \"unimatch_small\":\n",
    "                unimatch_input = {\"image1\": left_image, \"image2\": right_image}\n",
    "            elif model_type == \"pude\" or model_type == \"depth_anything\":\n",
    "                unimatch_input = left_image\n",
    "            if save_ground_truth:\n",
    "                org_rplot_path = f\"{org_unimatch_results_rplt_path}/image_{i}.png\"\n",
    "            else:\n",
    "                org_rplot_path = None\n",
    "            new_rplot_path = f\"{new_unimatch_results_rplt_path}/image_{i}.png\"\n",
    "            # new_rplot_path = None\n",
    "            # org_output, org_output_image, _org_evals, org_image_grid = get_model_output(org_unimatch_model, \n",
    "            #                                                                         org_unimatch_image_processor, \n",
    "            #                                                                         unimatch_input, \n",
    "            #                                                                         ground_truth,\n",
    "            #                                                                             valid_indices, device, rplot_path=org_rplot_path)\n",
    "            new_output, new_output_image, _new_evals, new_image_grid = get_model_output(new_unimatch_model, \n",
    "                                                                                    new_unimatch_image_processor, \n",
    "                                                                                    unimatch_input, \n",
    "                                                                                    ground_truth,\n",
    "                                                                                    valid_indices,device, rplot_path=new_rplot_path )\n",
    "\n",
    "            new_evals+=_new_evals\n",
    "            # org_evals+=_org_evals\n",
    "            # orig_unimatch_results.append(org_output)\n",
    "\n",
    "            # diff_image = pude_utils.get_depth_as_image(np.abs(org_output-new_output))\n",
    "            # diff_grid = pude_utils.make_image_grid_title(images=[Image.fromarray(left_image), org_output_image, new_output_image, diff_image],\n",
    "            #                                                 titles=[\"Left Image\", f\"Original {model_type} Output\", f\"New {model_type} Output\", \"Absolute Difference\"],\n",
    "            #                                                 rows=1, cols=4)\n",
    "            # combined_grid = pude_utils.make_image_grid_title(images=[org_image_grid, new_image_grid, diff_grid],\n",
    "            #                                                 titles=[f\"Original {model_type}\", f\"New {model_type}\", \"Difference\"],\n",
    "            #                                                 rows=3, cols=1)\n",
    "            # if save_ground_truth:\n",
    "            #     org_image_grid.save(f\"{org_unimatch_results_path}/image_{i}.png\")\n",
    "            new_image_grid.save(f\"{new_unimatch_results_path}/image_{i}.png\")\n",
    "            # combined_grid.save(f\"{combined_grid_path}/image_{i}.png\")\n",
    "\n",
    "\n",
    "        new_evals/=total_images\n",
    "        # org_evals/=total_images\n",
    "\n",
    "        print(f\"-------------------{dataset_name} Results-------------------\")\n",
    "        # print(\"original unimatch: \")\n",
    "        # print(stereo_evaluator.criteria_functions.keys())\n",
    "        # print(org_evals)\n",
    "        print(f\"{model_path[:-4]}: \")\n",
    "        print(stereo_evaluator.criteria_functions.keys())\n",
    "        print(new_evals)\n",
    "        print(\"------------------------------------------------------------\")\n",
    "        # if save_ground_truth:\n",
    "        #     with open(f\"Results/FLSea/{dataset_name}/orig_{model_type}_results.pkl\", \"wb\") as f:\n",
    "        #         pickle.dump(orig_unimatch_results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
